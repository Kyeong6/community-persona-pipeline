name: Weekly Crawling

on:
  schedule:
    # 매주 월요일 오전 2시 (UTC) = 한국시간 오전 11시
    - cron: '0 2 * * 1'
  workflow_dispatch:  # 수동 실행 가능

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 최대 4시간 (2시간 작업 + 여유)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: true
      
      - name: Install Playwright browsers
        run: poetry run playwright install chromium
      
      - name: Install dependencies
        run: poetry install --no-interaction --no-root
      
      - name: Install project
        run: poetry install --no-interaction
      
      - name: Configure environment variables
        env:
          NAVER_COOKIE: ${{ secrets.NAVER_COOKIE }}
          NAVER_ID: ${{ secrets.NAVER_ID }}
          NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
          BROWSER_HEADLESS: 'true'
          BROWSER_TIMEOUT: '60000'
        run: |
          echo "NAVER_COOKIE=${NAVER_COOKIE}" >> $GITHUB_ENV || true
          echo "NAVER_ID=${NAVER_ID}" >> $GITHUB_ENV || true
          echo "NAVER_PASSWORD=${NAVER_PASSWORD}" >> $GITHUB_ENV || true
          echo "BROWSER_HEADLESS=true" >> $GITHUB_ENV
          echo "BROWSER_TIMEOUT=60000" >> $GITHUB_ENV
      
      - name: Run Mamibebe crawler
        env:
          NAVER_COOKIE: ${{ secrets.NAVER_COOKIE }}
          NAVER_ID: ${{ secrets.NAVER_ID }}
          NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
          BROWSER_HEADLESS: 'true'
        run: poetry run python src/run_mamibebe.py
        continue-on-error: true  # 하나 실패해도 다른 작업 계속
      
      - name: Run Ppomppu crawler
        env:
          BROWSER_HEADLESS: 'true'
        run: poetry run python src/run_ppomppu.py
        continue-on-error: true
      
      - name: Upload results as artifacts
        uses: actions/upload-artifact@v4
        if: always()  # 실패해도 아티팩트 업로드
        with:
          name: crawling-results-${{ github.run_number }}
          path: outputs/
          retention-days: 30  # 30일간 보관
      
      - name: Summary
        if: always()
        run: |
          echo "## 크롤링 완료" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- 실행 시간: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- 결과 파일: outputs/ 디렉토리 확인" >> $GITHUB_STEP_SUMMARY
          ls -lh outputs/ || echo "출력 파일 없음"

