from src.crawlers.base_crawler import BaseCrawler
from src.models.post import Post
from typing import List
import httpx
import os
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

class MamibebeCrawler(BaseCrawler):
    def __init__(self):
        super().__init__()
        self.cafe_url = os.getenv('NAVER_CAFE_URL', 'https://cafe.naver.com/f-e/cafes/29434212/popular')
        self.community = "ë§˜ì´ë² ë² "
        self.club_id = None
    
    async def crawl(self, max_posts: int = 20) -> List[Post]:
        posts = []
        
        try:
            # 1. ë„¤ì´ë²„ ë¡œê·¸ì¸
            self.naver_cookies = await self.login_naver()
            
            # 2. Club ID ì¶”ì¶œ
            self.club_id = await self.get_club_id(self.cafe_url)
            
            # 3. ì¸ê¸°ê¸€ ID ëª©ë¡ ìˆ˜ì§‘
            post_ids = await self._get_popular_post_ids(max_posts)
            
            # 4. ê° ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            for i, post_id in enumerate(post_ids):
                try:
                    print(f"ğŸ«› ê²Œì‹œê¸€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {post_id} [{i+1}/{len(post_ids)}]")
                    
                    # ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´
                    post_data = await self._get_post_data(post_id)
                    if not post_data:
                        continue
                    
                    # ëŒ“ê¸€ ë° ì¢‹ì•„ìš” ì •ë³´
                    extra_data = await self._get_post_extra_data(post_id)
                    
                    # Post ê°ì²´ ìƒì„±
                    post = Post(
                        title=post_data["article"]["subject"],
                        url=f"https://cafe.naver.com/f-e/cafes/{self.club_id}/articles/{post_id}",
                        views=post_data["article"]["readCount"],
                        comments=post_data["article"]["commentCount"],
                        likes=len(extra_data.get("likeItUsers", [])) if extra_data else 0,
                        community=self.community,
                        timestamp=datetime.now()
                    )
                    posts.append(post)
                    
                    # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                    await self.page.wait_for_timeout(1000)
                    
                except Exception as e:
                    print(f"ê²Œì‹œê¸€ {post_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"ë§˜ì´ë² ë²  í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        print(f"ğŸ«› ì´ {len(posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
        return posts
    
    async def _get_popular_post_ids(self, max_posts: int) -> List[int]:
        """ì¸ê¸°ê¸€ ID ëª©ë¡ ìˆ˜ì§‘"""
        print(f"ğŸ«› ì¸ê¸°ê¸€ ID ëª©ë¡ ìˆ˜ì§‘ ì¤‘... (ìµœëŒ€ {max_posts}ê°œ)")
        
        post_ids = []
        page_num = 1
        
        async with httpx.AsyncClient(cookies=self.naver_cookies) as client:
            while len(post_ids) < max_posts:
                try:
                    # ì¸ê¸°ê¸€ ëª©ë¡ API í˜¸ì¶œ
                    response = await client.get(
                        f"https://apis.naver.com/cafe-web/cafe-search-api/v1.0/cafes/{self.club_id}/search/articles",
                        params={
                            "query": "",  # ë¹ˆ ì¿¼ë¦¬ë¡œ ì „ì²´ ê²€ìƒ‰
                            "perPage": 15,
                            "page": page_num,
                            "views": "MEMBER_LEVEL,COUNT,SALE_INFO,CAFE_MENU",
                        }
                    )
                    response.raise_for_status()
                    data = response.json()
                    
                    result = data["result"]
                    article_list = result["articleList"]
                    
                    if not article_list:
                        break
                    
                    # ê²Œì‹œê¸€ ID ì¶”ì¶œ
                    for article in article_list:
                        if len(post_ids) >= max_posts:
                            break
                        post_id = article["item"]["articleId"]
                        post_ids.append(post_id)
                    
                    # í˜ì´ì§€ ì •ë³´ í™•ì¸
                    page_info = result["pageInfo"]
                    if page_num >= page_info["lastNavigationPageNumber"]:
                        break
                    
                    page_num += 1
                    
                except Exception as e:
                    print(f"í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                    break
        
        print(f"ğŸ«› {len(post_ids)}ê°œ ì¸ê¸°ê¸€ ID ìˆ˜ì§‘ ì™„ë£Œ")
        return post_ids[:max_posts]
    
    async def _get_post_data(self, post_id: int) -> dict:
        """ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        try:
            async with httpx.AsyncClient(cookies=self.naver_cookies) as client:
                response = await client.get(
                    f"https://article.cafe.naver.com/gw/v4/cafes/{self.club_id}/articles/{post_id}"
                )
                
                if response.status_code == 403:
                    print(f"ğŸ«›âŒ ê²Œì‹œê¸€ {post_id} ì ‘ê·¼ ê±°ë¶€ë¨")
                    return None
                elif response.status_code != 200:
                    print(f"ğŸ«›âŒ ê²Œì‹œê¸€ {post_id} ìƒíƒœ ì½”ë“œ: {response.status_code}")
                    return None
                
                data = response.json()
                return data["result"]
                
        except Exception as e:
            print(f"ê²Œì‹œê¸€ {post_id} ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _get_post_extra_data(self, post_id: int) -> dict:
        """ê²Œì‹œê¸€ ëŒ“ê¸€ ë° ì¢‹ì•„ìš” ì •ë³´ ìˆ˜ì§‘"""
        try:
            async with httpx.AsyncClient(cookies=self.naver_cookies) as client:
                response = await client.get(
                    f"https://article.cafe.naver.com/gw/v4/cafes/{self.club_id}/articles/{post_id}/comments/pages/1"
                )
                response.raise_for_status()
                data = response.json()
                return data["result"]
                
        except Exception as e:
            print(f"ê²Œì‹œê¸€ {post_id} ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None