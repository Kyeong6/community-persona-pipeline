from src.crawlers.base_crawler import BaseCrawler
from src.models.post import Post
from typing import List, Set
import httpx
import os
import re
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

class MamibebeCrawler(BaseCrawler):
    def __init__(self):
        super().__init__()
        self.cafe_main_url = "https://cafe.naver.com/skybluezw4rh"
        self.popular_url = "https://cafe.naver.com/f-e/cafes/29434212/popular"
        self.club_id = 29434212
        self.channel = "mam2bebe"
    
    async def crawl(self, max_posts: int = None) -> List[Post]:
        """ë§˜ì´ë² ë²  ì¸ê¸°ê¸€ í¬ë¡¤ë§ (ì˜¤ëŠ˜ ê¸°ì¤€ ì¼ì£¼ì¼ ì „ê¹Œì§€)"""
        posts = []
        
        try:
            # 1. ë„¤ì´ë²„ ë¡œê·¸ì¸
            self.naver_cookies = await self.login_naver()
            
            # 2. ì¹´í˜ ì…ì¥
            print(f"ğŸ«› ì¹´í˜ ì…ì¥: {self.cafe_main_url}")
            await self.page.goto(self.cafe_main_url, wait_until="load")
            await self.page.wait_for_timeout(2000)
            
            # 3. ì¸ê¸°ê¸€ í˜ì´ì§€ ì ‘ì†
            print(f"ğŸ«› ì¸ê¸°ê¸€ í˜ì´ì§€ ì ‘ì†: {self.popular_url}")
            await self.page.goto(self.popular_url, wait_until="load")
            await self.page.wait_for_timeout(2000)
            
            # 4. ê²Œì‹œê¸€ URL ëª©ë¡ ìˆ˜ì§‘ (ì¼ì£¼ì¼ ì „ê¹Œì§€ í•„í„°ë§)
            post_urls = await self._get_posts_from_popular_page(max_posts)
            print(f"ğŸ«› ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ URL: {len(post_urls)}ê°œ")
            
            # 5. ê° ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            for i, post_url in enumerate(post_urls):
                try:
                    print(f"ğŸ«› ê²Œì‹œê¸€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {post_url} [{i+1}/{len(post_urls)}]")
                    
                    # ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ ì ‘ì†
                    await self.page.goto(post_url, wait_until="load")
                    await self.page.wait_for_timeout(2000)
                    
                    # ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ
                    post = await self._extract_post_data(post_url)
                    if post:
                        # ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ì—ì„œë„ ì¹´ì¹´ì˜¤í˜ì´ ì¶”ì²œì¸ ê²Œì‹œë¬¼ ì œì™¸
                        title_normalized = post.title.strip() if post.title else ""
                        if 'ì¹´ì¹´ì˜¤í˜ì´' in title_normalized:
                            if 'ì¦ê¶Œ ì¶”ì²œì¸' in title_normalized or 'í”¼ìë§Œë“¤ê¸° ì¶”ì²œì¸' in title_normalized:
                                print(f"ğŸ«› ì œì™¸: ì¹´ì¹´ì˜¤í˜ì´ ì¶”ì²œì¸ ê²Œì‹œë¬¼ (ìƒì„¸) - {title_normalized[:50]}")
                                continue
                        posts.append(post)
                    
                    # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                    await self.page.wait_for_timeout(1000)
                    
                except Exception as e:
                    print(f"ê²Œì‹œê¸€ {post_url} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"ë§˜ì´ë² ë²  í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"ğŸ«› ì´ {len(posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
        return posts
    
    async def _get_posts_from_popular_page(self, max_posts: int = None) -> List[str]:
        """ì¸ê¸°ê¸€ í˜ì´ì§€ì—ì„œ ê²Œì‹œê¸€ URLì„ ìˆ˜ì§‘ (ì˜¤ëŠ˜ ê¸°ì¤€ ì¼ì£¼ì¼ ì „ê¹Œì§€)"""
        print(f"ğŸ«› ì¸ê¸°ê¸€ URL ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
        
        # ë‚ ì§œ í•„í„°: ì˜¤ëŠ˜ ê¸°ì¤€ ì¼ì£¼ì¼ ì „
        today = datetime.now()
        week_ago = today - timedelta(days=7)
        print(f"ğŸ«› ë‚ ì§œ í•„í„°: {week_ago.strftime('%Y-%m-%d')} ~ {today.strftime('%Y-%m-%d')}")

        # ë³¸ë¬¸ì€ iframe#cafe_main ì•ˆì— ë¡œë“œë¨
        try:
            iframe_elem = await self.page.wait_for_selector("iframe#cafe_main", timeout=10000)
            frame = await iframe_elem.content_frame()
        except Exception as e:
            print(f"ğŸ«›âŒ ì¸ê¸°ê¸€ iframe íƒìƒ‰ ì‹¤íŒ¨: {e}")
            frame = None

        if frame is None:
            print("ğŸ«›âŒ iframeì„ ì°¾ì§€ ëª»í•´ URL ì¶”ì¶œ ë¶ˆê°€")
            return []

        collected_urls: List[str] = []  # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        current_page = 1
        max_pages = 12  # ìµœëŒ€ 12í˜ì´ì§€ê¹Œì§€
        
        # í˜ì´ì§€ë„¤ì´ì…˜ì„ ë”°ë¼ ëª¨ë“  í˜ì´ì§€ ìˆ˜ì§‘
        while current_page <= max_pages:
            print(f"ğŸ«› [í˜ì´ì§€ {current_page}] ê²Œì‹œê¸€ ìˆ˜ì§‘ ì‹œì‘... í˜„ì¬ {len(collected_urls)}ê°œ")
            
            # í˜„ì¬ í˜ì´ì§€ì—ì„œ ê²Œì‹œê¸€ URL ì¶”ì¶œ
            items: List[dict] = await frame.evaluate(
                r"""
                (() => {
                  const items = [];
                  // ê²Œì‹œê¸€ í–‰ì´ë‚˜ í•­ëª© ì°¾ê¸°
                  const rows = Array.from(document.querySelectorAll('tr, li, .article_item, [class*="article"]'));
                  
                  for (const row of rows) {
                    const anchor = row.querySelector('a[href*="/articles/"], a[href*="skybluezw4rh"]');
                    if (!anchor) continue;
                    
                    const href = anchor.getAttribute('href');
                    if (!href) continue;
                    
                    // URL íŒ¨í„´ ë§¤ì¹­
                    const urlMatch = href.match(/(?:articles\/(\d+)|skybluezw4rh\/(\d+))/);
                    if (!urlMatch) continue;
                    
                    const articleId = urlMatch[1] || urlMatch[2];
                    if (!articleId) continue;
                    
                    // ì œëª© ì¶”ì¶œ
                    const titleText = anchor.innerText.trim() || anchor.textContent.trim();
                    
                    // ë‚ ì§œ ì •ë³´ ì°¾ê¸°
                    let dateText = '';
                    const dateEl = row.querySelector('.date, .time, [class*="date"], [class*="time"], td.date');
                    if (dateEl) dateText = dateEl.innerText.trim();
                    
                    // ì „ì²´ URL ìƒì„±
                    let fullUrl = href;
                    if (href.startsWith('/')) {
                      fullUrl = 'https://cafe.naver.com' + href;
                    } else if (href.includes('skybluezw4rh')) {
                      if (!href.startsWith('http')) {
                        fullUrl = 'https://cafe.naver.com/' + href;
                      }
                    }
                    
                    items.push({
                      url: fullUrl,
                      articleId: articleId,
                      title: titleText,
                      dateText: dateText
                    });
                  }
                  return items;
                })()
                """
            )
            print(f"ğŸ«› [í˜ì´ì§€ {current_page}] í™”ë©´ì—ì„œ ë°œê²¬ëœ ê²Œì‹œê¸€ ìˆ˜: {len(items)}")

            before_len = len(collected_urls)
            for item in items:
                url = item.get('url', '')
                title = item.get('title', '')
                date_text = item.get('dateText', '')
                
                # ì¹´ì¹´ì˜¤í˜ì´ ì¶”ì²œì¸ ê²Œì‹œë¬¼ ì œì™¸
                # ì œëª©ì—ì„œ ê³µë°± ì œê±° í›„ ì •í™•íˆ ë§¤ì¹­
                if title:
                    title_normalized = title.strip()
                    # "ì¹´ì¹´ì˜¤í˜ì´ ì¦ê¶Œ ì¶”ì²œì¸" ë˜ëŠ” "ì¹´ì¹´ì˜¤í˜ì´ í”¼ìë§Œë“¤ê¸° ì¶”ì²œì¸" í¬í•¨ ì—¬ë¶€ í™•ì¸
                    if 'ì¹´ì¹´ì˜¤í˜ì´' in title_normalized:
                        if 'ì¦ê¶Œ ì¶”ì²œì¸' in title_normalized or 'í”¼ìë§Œë“¤ê¸° ì¶”ì²œì¸' in title_normalized:
                            print(f"ğŸ«› ì œì™¸: ì¹´ì¹´ì˜¤í˜ì´ ì¶”ì²œì¸ ê²Œì‹œë¬¼ - {title_normalized[:50]}")
                            continue
                
                # ë‚ ì§œ í•„í„°ë§ (ì¼ì£¼ì¼ ì „ê¹Œì§€)
                if date_text:
                    post_date = self._parse_date(date_text)
                    if post_date and post_date < week_ago:
                        continue  # ì¼ì£¼ì¼ ì´ì „ ê²Œì‹œê¸€ì€ ì œì™¸
                
                # ì¤‘ë³µ ì²´í¬ (URL ê¸°ë°˜)
                if url and url not in collected_urls:
                    collected_urls.append(url)  # ìˆœì„œ ìœ ì§€
                
                # max_posts ì œí•œì´ ìˆìœ¼ë©´ ì²´í¬
                if max_posts and len(collected_urls) >= max_posts:
                    break

            after_len = len(collected_urls)
            new_count = after_len - before_len
            print(f"ğŸ«› [í˜ì´ì§€ {current_page}] ì‹ ê·œ ìˆ˜ì§‘: {new_count}ê°œ, ëˆ„ì : {after_len}ê°œ")

            # max_postsì— ë„ë‹¬í•˜ë©´ ì¢…ë£Œ
            if max_posts and len(collected_urls) >= max_posts:
                print(f"ğŸ«› max_posts({max_posts})ì— ë„ë‹¬í•˜ì—¬ ìˆ˜ì§‘ ì¢…ë£Œ")
                break

            # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            if current_page < max_pages:
                next_page_clicked = False
                used_right_arrow = False  # '>' ë²„íŠ¼ ì‚¬ìš© ì—¬ë¶€
                next_page_num = current_page + 1
                try:
                    # ë¨¼ì € ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼ì´ ìˆëŠ”ì§€ í™•ì¸
                    next_page_num_exists = await frame.evaluate(f"""
                        (() => {{
                            const nextNum = {next_page_num};
                            const buttons = Array.from(document.querySelectorAll('a, button, span'));
                            for (const btn of buttons) {{
                                const text = btn.innerText.trim();
                                if (text === String(nextNum)) {{
                                    // í˜„ì¬ í˜ì´ì§€ì¸ì§€ í™•ì¸ (í™œì„±í™” ìƒíƒœë©´ ìŠ¤í‚µ)
                                    const parent = btn.closest('div, li, span');
                                    if (parent && (parent.className.includes('active') || parent.className.includes('current'))) {{
                                        return false;
                                    }}
                                    // í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œì¸ì§€ í™•ì¸
                                    if (btn.style.display !== 'none' && btn.offsetParent !== null) {{
                                        return true;
                                    }}
                                }}
                            }}
                            return false;
                        }})()
                    """)
                    
                    # ë°©ë²• 1: ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼ì´ ìˆìœ¼ë©´ í´ë¦­
                    if next_page_num_exists:
                        clicked = await frame.evaluate(f"""
                            (() => {{
                                const nextNum = {next_page_num};
                                const buttons = Array.from(document.querySelectorAll('a, button'));
                                for (const btn of buttons) {{
                                    const text = btn.innerText.trim();
                                    if (text === String(nextNum)) {{
                                        const parent = btn.closest('div, li, span');
                                        if (parent && (parent.className.includes('active') || parent.className.includes('current'))) {{
                                            continue;
                                        }}
                                        if (btn.style.display !== 'none' && btn.offsetParent !== null) {{
                                            btn.click();
                                            return true;
                                        }}
                                    }}
                                }}
                                return false;
                            }})()
                        """)
                        if clicked:
                            next_page_clicked = True
                            print(f"ğŸ«› í˜ì´ì§€ {next_page_num} ë²„íŠ¼ í´ë¦­ ì„±ê³µ")
                    
                    # ë°©ë²• 2: ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ 'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­ (10í˜ì´ì§€ ì´í›„)
                    if not next_page_clicked:
                        # ë°©ë²• 2-1: button.type_next í´ë˜ìŠ¤ ì°¾ê¸°
                        next_button_clicked = await frame.evaluate("""
                            (() => {
                                // class="btn type_next" ë²„íŠ¼ ì°¾ê¸°
                                const buttons = Array.from(document.querySelectorAll('button.type_next, button[class*="type_next"], .type_next'));
                                for (const btn of buttons) {
                                    // ë¹„í™œì„±í™” ìƒíƒœ í™•ì¸
                                    if (btn.disabled || btn.className.includes('disabled')) {
                                        continue;
                                    }
                                    // í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œì¸ì§€ í™•ì¸
                                    if (btn.style.display !== 'none' && btn.offsetParent !== null) {
                                        btn.click();
                                        return true;
                                    }
                                }
                                return false;
                            })()
                        """)
                        if next_button_clicked:
                            next_page_clicked = True
                            used_right_arrow = True
                            print(f"ğŸ«› ë‹¤ìŒ ë²„íŠ¼(type_next) í´ë¦­ ì„±ê³µ - í˜ì´ì§€ {next_page_num} í‘œì‹œ ì˜ˆì •")
                        
                        # ë°©ë²• 2-2: aria-label="ë‹¤ìŒ" ë˜ëŠ” SVG ë‚´ aria-label="ë‹¤ìŒ" ì°¾ê¸°
                        if not next_page_clicked:
                            aria_next_clicked = await frame.evaluate("""
                                (() => {
                                    // aria-label="ë‹¤ìŒ"ì´ ìˆëŠ” ë²„íŠ¼ ë˜ëŠ” SVG ì°¾ê¸°
                                    const buttons = Array.from(document.querySelectorAll('button, a'));
                                    for (const btn of buttons) {
                                        // ë²„íŠ¼ ìì²´ì— aria-labelì´ ìˆê±°ë‚˜
                                        if (btn.getAttribute('aria-label') === 'ë‹¤ìŒ') {
                                            if (!btn.disabled && btn.style.display !== 'none' && btn.offsetParent !== null) {
                                                btn.click();
                                                return true;
                                            }
                                        }
                                        // ë²„íŠ¼ ë‚´ë¶€ì˜ SVGì— aria-label="ë‹¤ìŒ"ì´ ìˆëŠ” ê²½ìš°
                                        const svg = btn.querySelector('svg[aria-label="ë‹¤ìŒ"]');
                                        if (svg) {
                                            if (!btn.disabled && btn.style.display !== 'none' && btn.offsetParent !== null) {
                                                btn.click();
                                                return true;
                                            }
                                        }
                                    }
                                    return false;
                                })()
                            """)
                            if aria_next_clicked:
                                next_page_clicked = True
                                used_right_arrow = True
                                print(f"ğŸ«› ë‹¤ìŒ ë²„íŠ¼(aria-label) í´ë¦­ ì„±ê³µ - í˜ì´ì§€ {next_page_num} í‘œì‹œ ì˜ˆì •")
                        
                        # ë°©ë²• 2-3: '>' í…ìŠ¤íŠ¸ ë²„íŠ¼ ì°¾ê¸° (fallback)
                        if not next_page_clicked:
                            right_arrow_clicked = await frame.evaluate("""
                                (() => {
                                    // '>' ë²„íŠ¼ ì°¾ê¸° (ë‹¨ì¼ í™”ì‚´í‘œ)
                                    const buttons = Array.from(document.querySelectorAll('a, button'));
                                    for (const btn of buttons) {
                                        const text = btn.innerText.trim();
                                        // ì •í™•íˆ '>' ë¬¸ìë§Œ ìˆëŠ” ë²„íŠ¼ ì°¾ê¸° (>>ëŠ” ì œì™¸)
                                        if (text === '>') {
                                            // ë¹„í™œì„±í™” ìƒíƒœ í™•ì¸
                                            if (btn.disabled || btn.className.includes('disabled')) {
                                                continue;
                                            }
                                            // í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œì¸ì§€ í™•ì¸
                                            if (btn.style.display !== 'none' && btn.offsetParent !== null) {
                                                btn.click();
                                                return true;
                                            }
                                        }
                                    }
                                    return false;
                                })()
                            """)
                            if right_arrow_clicked:
                                next_page_clicked = True
                                used_right_arrow = True
                                print(f"ğŸ«› ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼(>) í´ë¦­ ì„±ê³µ - í˜ì´ì§€ {next_page_num} í‘œì‹œ ì˜ˆì •")
                    
                    if next_page_clicked:
                        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                        await self.page.wait_for_timeout(3000)
                        # iframe ì¬ì°¸ì¡° (í˜ì´ì§€ ì „í™˜ í›„)
                        try:
                            iframe_elem = await self.page.wait_for_selector("iframe#cafe_main", timeout=5000)
                            frame = await iframe_elem.content_frame()
                            
                            # '>' ë²„íŠ¼ì„ í´ë¦­í•œ ê²½ìš°, ë‹¤ìŒì— ë‚˜íƒ€ë‚˜ëŠ” í˜ì´ì§€ ë²ˆí˜¸ë¥¼ í™•ì¸
                            if used_right_arrow:
                                # í˜ì´ì§€ë„¤ì´ì…˜ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
                                await self.page.wait_for_timeout(1000)
                                # í™œì„±í™”ëœ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
                                active_page = await frame.evaluate("""
                                    (() => {
                                        const buttons = Array.from(document.querySelectorAll('a, button, span'));
                                        for (const btn of buttons) {
                                            const parent = btn.closest('div, li, span');
                                            if (parent && (parent.className.includes('active') || parent.className.includes('current'))) {
                                                const text = btn.innerText.trim();
                                                const num = parseInt(text);
                                                if (!isNaN(num)) {
                                                    return num;
                                                }
                                            }
                                        }
                                        return null;
                                    })()
                                """)
                                if active_page:
                                    current_page = active_page
                                    print(f"ğŸ«› í˜ì´ì§€ {current_page} ë¡œë“œ ì™„ë£Œ (í™œì„± í˜ì´ì§€ ê°ì§€)")
                                else:
                                    current_page += 1
                                    print(f"ğŸ«› í˜ì´ì§€ {current_page} ë¡œë“œ ì™„ë£Œ (ì¶”ì •)")
                            else:
                                current_page += 1
                                print(f"ğŸ«› í˜ì´ì§€ {current_page} ë¡œë“œ ì™„ë£Œ")
                        except Exception as e:
                            print(f"ğŸ«›âŒ í˜ì´ì§€ {next_page_num} ë¡œë“œ ì‹¤íŒ¨: {e}")
                            break
                    else:
                        print(f"ğŸ«›âŒ í˜ì´ì§€ {next_page_num} ë²„íŠ¼ì„ ì°¾ì§€ ëª»í•¨. ìˆ˜ì§‘ ì¢…ë£Œ")
                        break
                    
                except Exception as e:
                    print(f"ğŸ«›âŒ í˜ì´ì§€ë„¤ì´ì…˜ í´ë¦­ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    break
            else:
                print(f"ğŸ«› ìµœëŒ€ í˜ì´ì§€({max_pages})ì— ë„ë‹¬í•˜ì—¬ ìˆ˜ì§‘ ì¢…ë£Œ")
                break
        
        # max_posts ì œí•œ ì ìš©
        if max_posts:
            post_urls = collected_urls[:max_posts]
        else:
            post_urls = collected_urls
        print(f"ğŸ«› ì´ {len(post_urls)}ê°œ ì¸ê¸°ê¸€ URL ìˆ˜ì§‘ ì™„ë£Œ (ì´ {current_page}í˜ì´ì§€ ìˆœíšŒ)")
        return post_urls
    
    def _parse_date(self, date_text: str) -> datetime:
        """ë‚ ì§œ í…ìŠ¤íŠ¸ë¥¼ datetimeìœ¼ë¡œ íŒŒì‹±"""
        if not date_text:
            return None
        
        try:
            date_text = date_text.strip()
            
            # "2025.11.02. 12:39" í˜•ì‹ (ë‚ ì§œì™€ ì‹œê°„ ëª¨ë‘ í¬í•¨)
            datetime_match = re.match(r'(\d{4})\.(\d{1,2})\.(\d{1,2})\.?\s*(\d{1,2}):(\d{1,2})', date_text)
            if datetime_match:
                year, month, day, hour, minute = datetime_match.groups()
                return datetime(int(year), int(month), int(day), int(hour), int(minute))
            
            # "2025.11.02" í˜•ì‹ (ë‚ ì§œë§Œ)
            date_only_match = re.match(r'(\d{4})\.(\d{1,2})\.(\d{1,2})', date_text)
            if date_only_match:
                year, month, day = date_only_match.groups()
                return datetime(int(year), int(month), int(day))
            
            # "10.14" í˜•ì‹ (ì˜¬í•´ ê°€ì •)
            if re.match(r'\d{1,2}\.\d{1,2}', date_text):
                today = datetime.now()
                parts = date_text.split('.')
                return datetime(today.year, int(parts[0]), int(parts[1]))
            
            # "10-14" í˜•ì‹
            if re.match(r'\d{1,2}-\d{1,2}', date_text):
                today = datetime.now()
                parts = date_text.split('-')
                return datetime(today.year, int(parts[0]), int(parts[1]))
            
            # "ì–´ì œ", "ì˜¤ëŠ˜" ë“±ì˜ í…ìŠ¤íŠ¸
            if 'ì˜¤ëŠ˜' in date_text or 'today' in date_text.lower():
                return datetime.now()
            if 'ì–´ì œ' in date_text or 'yesterday' in date_text.lower():
                return datetime.now() - timedelta(days=1)
                
        except Exception as e:
            print(f"ğŸ«› ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {date_text}, {e}")
            pass
        return None
    
    def _format_datetime(self, dt: datetime) -> str:
        """datetimeì„ "2025-11-02 12:39" í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not dt:
            return None
        return dt.strftime('%Y-%m-%d %H:%M')
    
    async def _extract_post_data(self, post_url: str) -> Post:
        """ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # iframe ë‚´ë¶€ ì ‘ê·¼
            try:
                iframe_elem = await self.page.wait_for_selector("iframe#cafe_main", timeout=5000)
                frame = await iframe_elem.content_frame()
            except:
                frame = self.page
            
            # ê²Œì‹œê¸€ ID ì¶”ì¶œ
            article_id_match = re.search(r'skybluezw4rh/(\d+)', post_url)
            article_id = int(article_id_match.group(1)) if article_id_match else None
            
            # ì œëª© ì¶”ì¶œ
            title = ""
            title_selectors = [
                'h3.title_text',
                '.title_text',
                'h3[class*="title"]',
                '.ArticleTitle',
                'h3'
            ]
            for sel in title_selectors:
                try:
                    title_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if title_elem:
                        title = await title_elem.inner_text()
                        if title:
                            break
                except:
                    continue
            
            # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ëª…ì´ ìˆìœ¼ë©´)
            category = None
            category_selectors = [
                '.category',
                '[class*="category"]',
                '.board_name',
                '.menu_name'
            ]
            for sel in category_selectors:
                try:
                    cat_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if cat_elem:
                        category = await cat_elem.inner_text()
                        if category:
                            break
                except:
                    continue
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ (í…ìŠ¤íŠ¸ë§Œ, ì´ë¯¸ì§€/ë§í¬ ì œì™¸, ì¤„ë°”ê¿ˆ ìœ ì§€)
            content = ""
            content_selectors = [
                '.se-main-container',
                '.article_container',
                'div.article_container',
                '.article_body',
                '[class*="article_container"]',
                '[class*="article"] [class*="body"]',
                '.ContentRenderer',
                '.article_viewer'
            ]
            
            # ë°©ë²• 1: ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• - innerText ì§ì ‘ ì‚¬ìš©
            for sel in content_selectors:
                try:
                    content_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if content_elem:
                        # innerTextëŠ” ì´ë¯¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•¨ (ì´ë¯¸ì§€/ë§í¬ ì œì™¸)
                        content = await content_elem.inner_text()
                        if content:
                            # ì¤„ë°”ê¿ˆ ì •ë¦¬ (ë¹ˆ ì¤„ ì œê±°)
                            lines = [line.strip() for line in content.split('\n') if line.strip()]
                            content = '\n'.join(lines)
                            if len(content) > 10:  # ì˜ë¯¸ìˆëŠ” ê¸¸ì´ì¸ì§€ í™•ì¸
                                print(f"ğŸ«› ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ (ì„ íƒì: {sel}): {len(content)}ì")
                                break
                except Exception as e:
                    continue
            
            # ë°©ë²• 2: frameì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„ (innerTextë¡œ)
            if not content and frame:
                try:
                    # ê°€ì¥ ì¼ë°˜ì ì¸ ì„ íƒìë¶€í„° ì‹œë„
                    containers = await frame.query_selector_all('.se-main-container, .article_container, [class*="article_container"]')
                    for container in containers:
                        try:
                            content = await container.inner_text()
                            if content:
                                lines = [line.strip() for line in content.split('\n') if line.strip()]
                                content = '\n'.join(lines)
                                if len(content) > 10:
                                    print(f"ğŸ«› ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ (iframe ì§ì ‘): {len(content)}ì")
                                    break
                        except:
                            continue
                except Exception as e:
                    print(f"ğŸ«› ë³¸ë¬¸ ì¶”ì¶œ ì˜¤ë¥˜ (iframe): {e}")
            
            # ì¡°íšŒìˆ˜ ì¶”ì¶œ ("ì¡°íšŒ 3,907" í˜•ì‹)
            view_cnt = 0
            view_selectors = [
                'span.count',  # ì´ë¯¸ì§€ì—ì„œ í™•ì¸ëœ ì„ íƒì
                '.count',
                '[class*="count"]',
                'span[class*="view"]',
                '[class*="view"]',
                '[class*="read"]'
            ]
            for sel in view_selectors:
                try:
                    view_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if view_elem:
                        view_text = await view_elem.inner_text()
                        # "ì¡°íšŒ 3,907" í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì‰¼í‘œ í¬í•¨ ê°€ëŠ¥)
                        view_match = re.search(r'ì¡°íšŒ\s*([\d,]+)', view_text)
                        if view_match:
                            # ì‰¼í‘œ ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜
                            view_num_str = view_match.group(1).replace(',', '')
                            view_cnt = int(view_num_str)
                            print(f"ğŸ«› ì¡°íšŒìˆ˜ ì¶”ì¶œ ì„±ê³µ: {view_text} -> {view_cnt}")
                            break
                except Exception as e:
                    continue
            
            # ì¡°íšŒìˆ˜ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° í˜ì´ì§€ ì „ì²´ì—ì„œ ê²€ìƒ‰
            if view_cnt == 0:
                try:
                    page_text = await (frame.evaluate("document.body.innerText") if frame else self.page.evaluate("document.body.innerText"))
                    view_match = re.search(r'ì¡°íšŒ\s*([\d,]+)', page_text)
                    if view_match:
                        view_num_str = view_match.group(1).replace(',', '')
                        view_cnt = int(view_num_str)
                        print(f"ğŸ«› ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ ì¡°íšŒìˆ˜ ì°¾ìŒ: {view_match.group(1)} -> {view_cnt}")
                except:
                    pass
            
            # ì¢‹ì•„ìš” ìˆ˜ ì¶”ì¶œ
            like_cnt = 0
            like_selectors = [
                '[class*="like"]',
                '[class*="recommend"]',
                '.LikeButton',
                'text=/ì¢‹ì•„ìš”\\s*\\d+/'
            ]
            for sel in like_selectors:
                try:
                    like_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if like_elem:
                        like_text = await like_elem.inner_text()
                        like_match = re.search(r'(\d+)', like_text)
                        if like_match:
                            like_cnt = int(like_match.group(1))
                            break
                except:
                    continue
            
            # ëŒ“ê¸€ ìˆ˜ ì¶”ì¶œ
            comment_cnt = 0
            comment_selectors = [
                '[class*="comment"]',
                '[class*="reply"]',
                '.CommentButton',
                'text=/ëŒ“ê¸€\\s*\\d+/'
            ]
            for sel in comment_selectors:
                try:
                    comment_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if comment_elem:
                        comment_text = await comment_elem.inner_text()
                        comment_match = re.search(r'(\d+)', comment_text)
                        if comment_match:
                            comment_cnt = int(comment_match.group(1))
                            break
                except:
                    continue
            
            # ì‘ì„±ì¼ì‹œ ì¶”ì¶œ ("2025.11.02. 12:39" í˜•ì‹)
            created_at = None
            date_selectors = [
                '.date',
                '[class*="date"]',
                '[class*="time"]',
                '.ArticleDate',
                '.article_info .date',
                '.article_info .time'
            ]
            for sel in date_selectors:
                try:
                    date_elem = await frame.query_selector(sel) if frame else await self.page.query_selector(sel)
                    if date_elem:
                        date_text = await date_elem.inner_text()
                        if date_text:
                            created_at = self._parse_date(date_text)
                            if created_at:
                                print(f"ğŸ«› ë‚ ì§œ íŒŒì‹± ì„±ê³µ: {date_text} -> {created_at}")
                                break
                except Exception as e:
                    continue
            
            # ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš° í˜ì´ì§€ ì „ì²´ì—ì„œ ê²€ìƒ‰
            if not created_at:
                try:
                    page_text = await (frame.evaluate("document.body.innerText") if frame else self.page.evaluate("document.body.innerText"))
                    date_match = re.search(r'(\d{4}\.\d{1,2}\.\d{1,2}\.?\s*\d{1,2}:\d{1,2})', page_text)
                    if date_match:
                        created_at = self._parse_date(date_match.group(1))
                        if created_at:
                            print(f"ğŸ«› ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ ë‚ ì§œ ì°¾ìŒ: {date_match.group(1)} -> {created_at}")
                except:
                    pass
            
            # URL ë³µì‚¬ ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì‹¤ì œ URL ê°€ì ¸ì˜¤ê¸°
            actual_url = post_url
            try:
                copy_btn = await frame.query_selector('button[class*="copy"], button[aria-label*="ë³µì‚¬"], .copy_url') if frame else await self.page.query_selector('button[class*="copy"], button[aria-label*="ë³µì‚¬"], .copy_url')
                if copy_btn:
                    await copy_btn.click()
                    await self.page.wait_for_timeout(500)
                    # í´ë¦½ë³´ë“œì—ì„œ URL ê°€ì ¸ì˜¤ê¸°
                    clipboard_text = await self.page.evaluate("navigator.clipboard.readText()")
                    if clipboard_text and 'skybluezw4rh' in clipboard_text:
                        actual_url = clipboard_text
            except:
                pass
            
            # own_company: ì œëª©ì— "ë¡¯ë°ì˜¨"ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0
            own_company = 1 if title and 'ë¡¯ë°ì˜¨' in title else 0
            
            # contentê°€ ì—†ê±°ë‚˜ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ì—†ìœ¼ë©´ None ë°˜í™˜ (pass)
            content_cleaned = content.strip() if content else ""
            if not content_cleaned or len(content_cleaned) < 10:
                print(f"ğŸ«› contentê°€ ì—†ì–´ì„œ ê²Œì‹œë¬¼ ì œì™¸: {post_url}")
                return None
            
            print(f"ğŸ«› ì¶”ì¶œ ì™„ë£Œ: title={title[:30]}..., view_cnt={view_cnt}, comment_cnt={comment_cnt}, like_cnt={like_cnt}")
            
            return Post(
                id=article_id,
                channel=self.channel,  # "mam2bebe" ê³ ì •
                category=category,
                title=title.strip() if title else "",
                content=content_cleaned,
                view_cnt=view_cnt,
                like_cnt=like_cnt,
                comment_cnt=comment_cnt,
                created_at=created_at,
                own_company=own_company,  # ì œëª©ì— "ë¡¯ë°ì˜¨" í¬í•¨ ì—¬ë¶€
                url=actual_url
            )
                
        except Exception as e:
            print(f"ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
