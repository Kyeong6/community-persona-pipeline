import asyncio
import json
import os
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

from src.crawlers.mamibebe_crawler import MamibebeCrawler


def ensure_outputs_dir() -> str:
    """outputs ë””ë ‰í† ë¦¬ ìƒì„±"""
    out_dir = os.path.join(os.getcwd(), "outputs")
    os.makedirs(out_dir, exist_ok=True)
    return out_dir


async def main() -> None:
    """ë§˜ì´ë² ë²  í¬ë¡¤ë§ ì‹¤í–‰"""
    max_posts_env = os.getenv("MAX_POSTS", "")
    max_posts = None
    if max_posts_env.strip():
        try:
            max_posts = int(max_posts_env)
        except Exception:
            max_posts = None

    async with MamibebeCrawler() as crawler:
        results = await crawler.crawl(max_posts=max_posts)
        
        # Post ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        payload = []
        for p in results:
            item = p.model_dump()
            
            # created_atì„ "2025-11-02 12:39" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if item.get("created_at"):
                if isinstance(item["created_at"], datetime):
                    item["created_at"] = item["created_at"].strftime('%Y-%m-%d %H:%M')
                elif isinstance(item["created_at"], str):
                    # ì´ë¯¸ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš© (ISO í˜•ì‹ì´ë©´ ë³€í™˜)
                    try:
                        dt = datetime.fromisoformat(item["created_at"].replace('Z', '+00:00'))
                        item["created_at"] = dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        pass
            
            # None ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if item.get("category") is None:
                item["category"] = ""
            if item.get("content") is None:
                item["content"] = ""
            
            # ë¶ˆí•„ìš”í•œ ì†ì„± ì œê±° (views, comments, likes, timestamp, community)
            item.pop("views", None)
            item.pop("comments", None)
            item.pop("likes", None)
            item.pop("timestamp", None)
            item.pop("community", None)
            
            payload.append(item)

        # JSON íŒŒì¼ë¡œ ì €ì¥
        out_dir = ensure_outputs_dir()
        ts_name = datetime.now().strftime("%Y%m%d_%H%M%S")
        fname = f"mamibebe_popular_{ts_name}.json"
        fpath = os.path.join(out_dir, fname)
        
        with open(fpath, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)

        print(f"\n{'='*60}")
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {fpath}")
        print(f"ğŸ“Š ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ ìˆ˜: {len(payload)}ê°œ")
        print(f"{'='*60}\n")
        
        # ìš”ì•½ ì¶œë ¥
        if payload:
            print("ğŸ“‹ ìˆ˜ì§‘ ìš”ì•½:")
            print(f"  - ì±„ë„: {payload[0].get('channel', 'N/A')}")
            print(f"  - ì œëª© ì˜ˆì‹œ: {payload[0].get('title', 'N/A')[:50]}...")
            print(f"  - ì¡°íšŒìˆ˜ ë²”ìœ„: {min(p.get('view_cnt', 0) for p in payload)} ~ {max(p.get('view_cnt', 0) for p in payload)}")
            print(f"  - ë¡¯ë°ì˜¨ ê²Œì‹œê¸€: {sum(1 for p in payload if p.get('own_company') == 1)}ê°œ")


if __name__ == "__main__":
    asyncio.run(main())

