import asyncio
import os
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

from src.crawlers.ppomppu_crawler import PpomppuCrawler


async def main() -> None:
    """ë½ë¿Œ í¬ë¡¤ë§ ì‹¤í–‰"""
    # MAX_POSTS ê¸°ë³¸ê°’: None (ê¸°ê°„ ë‚´ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘)
    max_posts_env = os.getenv("MAX_POSTS", "")
    max_posts = None  # ê¸°ë³¸ê°’: ê¸°ê°„ ë‚´ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
    if max_posts_env.strip():
        try:
            max_posts = int(max_posts_env)
            if max_posts == 0:  # 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ìˆ˜ì§‘
                max_posts = None
        except Exception:
            max_posts = None  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ None (ì „ì²´ ìˆ˜ì§‘)

    async with PpomppuCrawler() as crawler:
        results = await crawler.crawl(max_posts=max_posts)
        
        # Post ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        payload = []
        for p in results:
            item = p.model_dump()
            
            # created_atì„ "2025-11-02 12:39" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if item.get("created_at"):
                if isinstance(item["created_at"], datetime):
                    item["created_at"] = item["created_at"].strftime('%Y-%m-%d %H:%M')
                elif isinstance(item["created_at"], str):
                    # ì´ë¯¸ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš© (ISO í˜•ì‹ì´ë©´ ë³€í™˜)
                    try:
                        dt = datetime.fromisoformat(item["created_at"].replace('Z', '+00:00'))
                        item["created_at"] = dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        pass
            
            # None ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if item.get("category") is None:
                item["category"] = ""
            if item.get("content") is None:
                item["content"] = ""
            
            # ë¶ˆí•„ìš”í•œ ì†ì„± ì œê±° (views, comments, likes, timestamp, community)
            item.pop("views", None)
            item.pop("comments", None)
            item.pop("likes", None)
            item.pop("timestamp", None)
            item.pop("community", None)
            
            payload.append(item)

        print(f"\n{'='*60}")
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“Š ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ ìˆ˜: {len(payload)}ê°œ")
        print(f"{'='*60}\n")
        
        # ìš”ì•½ ì¶œë ¥
        if payload:
            print("ğŸ“‹ ìˆ˜ì§‘ ìš”ì•½:")
            print(f"  - ì±„ë„: {payload[0].get('channel', 'N/A')}")
            print(f"  - ì œëª© ì˜ˆì‹œ: {payload[0].get('title', 'N/A')[:50]}...")
            view_counts = [p.get('view_cnt', 0) for p in payload if p.get('view_cnt')]
            if view_counts:
                print(f"  - ì¡°íšŒìˆ˜ ë²”ìœ„: {min(view_counts)} ~ {max(view_counts)}")
            print(f"  - ë¡¯ë°ì˜¨ ê²Œì‹œê¸€: {sum(1 for p in payload if p.get('own_company') == 1)}ê°œ")
        
        # CSVì— ë°”ë¡œ ì €ì¥
        if payload:
            from src.utils.json_to_csv import append_posts_to_csv
            append_posts_to_csv(payload)


if __name__ == "__main__":
    asyncio.run(main())

