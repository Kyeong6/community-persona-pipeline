"""
JSON íŒŒì¼ë“¤ì„ CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ community_data.csvì— ì¶”ê°€í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
"""
import json
import os
import csv
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime


def get_last_id_and_existing_urls(csv_path: str) -> Tuple[int, set]:
    """ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ idì™€ ê¸°ì¡´ URLë“¤ì„ ê°€ì ¸ì˜´"""
    if not os.path.exists(csv_path):
        return 0, set()
    
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            last_id = 0
            existing_urls = set()
            
            for row in reader:
                try:
                    row_id = int(row.get('id', 0) or 0)
                    if row_id > last_id:
                        last_id = row_id
                except (ValueError, TypeError):
                    pass
                
                # ê¸°ì¡´ URL ìˆ˜ì§‘ (ì¤‘ë³µ ì²´í¬ìš©)
                url = row.get('url', '').strip()
                if url:
                    existing_urls.add(url)
            
            return last_id, existing_urls
    except Exception as e:
        print(f"âš ï¸ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return 0, set()


def load_json_files(outputs_dir: str) -> List[Dict]:
    """outputs ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  JSON íŒŒì¼ì„ ì½ì–´ì„œ í•©ì¹¨"""
    all_posts = []
    json_files = sorted(Path(outputs_dir).glob("*.json"))
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    all_posts.extend(data)
                    print(f"ğŸ“„ {json_file.name}: {len(data)}ê°œ ê²Œì‹œê¸€ ë¡œë“œ")
        except Exception as e:
            print(f"âš ï¸ {json_file.name} ì½ê¸° ì˜¤ë¥˜: {e}")
            continue
    
    return all_posts


def convert_to_csv_format(posts: List[Dict], start_id: int, existing_urls: set[str] = None) -> List[Dict]:
    """JSON í˜•ì‹ì˜ ê²Œì‹œê¸€ì„ CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  id í• ë‹¹ (ì¤‘ë³µ ì œê±°)"""
    if existing_urls is None:
        existing_urls = set()
    
    csv_rows = []
    current_id = start_id
    skipped_count = 0
    
    for post in posts:
        url = post.get('url', '').strip()
        
        # ì¤‘ë³µ ì²´í¬: URLì´ ì´ë¯¸ CSVì— ìˆìœ¼ë©´ ìŠ¤í‚µ
        if url and url in existing_urls:
            skipped_count += 1
            continue
        
        current_id += 1
        
        # CSV í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        csv_row = {
            'id': current_id,
            'channel': post.get('channel', ''),
            'category': post.get('category', ''),
            'title': post.get('title', ''),
            'content': post.get('content', ''),
            'view_cnt': post.get('view_cnt', 0) or 0,
            'like_cnt': post.get('like_cnt', 0) or 0,
            'comment_cnt': post.get('comment_cnt', 0) or 0,
            'created_at': post.get('created_at', ''),
            'own_company': post.get('own_company', 0) or 0,
            'url': url
        }
        
        csv_rows.append(csv_row)
        # ê¸°ì¡´ URL ëª©ë¡ì— ì¶”ê°€ (ê°™ì€ ë°°ì¹˜ ë‚´ ì¤‘ë³µ ë°©ì§€)
        if url:
            existing_urls.add(url)
    
    if skipped_count > 0:
        print(f"â­ï¸  ì¤‘ë³µ ì œê±°: {skipped_count}ê°œ ê²Œì‹œê¸€ ìŠ¤í‚µ")
    
    return csv_rows


def append_to_csv(csv_path: str, rows: List[Dict], append_mode: bool = True):
    """CSV íŒŒì¼ì— ë°ì´í„° ì¶”ê°€ ë˜ëŠ” ìƒˆë¡œ ì‘ì„±"""
    fieldnames = [
        'id', 'channel', 'category', 'title', 'content',
        'view_cnt', 'like_cnt', 'comment_cnt', 'created_at',
        'own_company', 'url'
    ]
    
    file_exists = os.path.exists(csv_path)
    
    mode = 'a' if append_mode and file_exists else 'w'
    newline = ''  # CSV writerëŠ” newline='' í•„ìš”
    
    with open(csv_path, mode, encoding='utf-8', newline=newline) as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_MINIMAL)
        
        # í—¤ë”ëŠ” íŒŒì¼ì´ ì—†ê±°ë‚˜ ìƒˆë¡œ ì‘ì„±í•  ë•Œë§Œ
        if mode == 'w' or not file_exists:
            writer.writeheader()
        
        # ë°ì´í„° ì‘ì„±
        for row in rows:
            writer.writerow(row)


def append_posts_to_csv(posts: List[Dict], csv_path: Optional[str] = None):
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë°”ë¡œ CSV íŒŒì¼ì— ì¶”ê°€ (JSON ì €ì¥ ì—†ì´)
    
    Args:
        posts: í¬ë¡¤ë§ìœ¼ë¡œ ì–»ì€ Post ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        csv_path: ì¶œë ¥í•  CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ./community_data.csv)
    """
    if csv_path is None:
        csv_path = os.path.join(os.getcwd(), "community_data.csv")
    
    if not posts:
        print("âš ï¸ ì¶”ê°€í•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸ“ CSV ì €ì¥ ì‹œì‘...")
    print(f"ğŸ“ CSV íŒŒì¼: {csv_path}")
    
    # 1. ê¸°ì¡´ CSVì—ì„œ ë§ˆì§€ë§‰ idì™€ ê¸°ì¡´ URL ëª©ë¡ í™•ì¸
    last_id, existing_urls = get_last_id_and_existing_urls(csv_path)
    print(f"ğŸ“Š ë§ˆì§€ë§‰ ID: {last_id}, ê¸°ì¡´ ê²Œì‹œê¸€ ìˆ˜: {len(existing_urls)}ê°œ")
    
    # 2. CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¤‘ë³µ ì œê±°)
    csv_rows = convert_to_csv_format(posts, last_id, existing_urls)
    
    if csv_rows:
        print(f"âœ… {len(csv_rows)}ê°œ ê²Œì‹œê¸€ ë³€í™˜ ì™„ë£Œ (ID: {last_id + 1} ~ {last_id + len(csv_rows)})")
        
        # 3. CSV íŒŒì¼ì— ì €ì¥
        append_to_csv(csv_path, csv_rows, append_mode=True)
        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
        print(f"ğŸ“Š ì´ {len(csv_rows)}ê°œ ê²Œì‹œê¸€ ì¶”ê°€ë¨")
    else:
        print("âš ï¸ ì¶”ê°€í•  ìƒˆ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ì¤‘ë³µ)")
    
    print(f"{'='*60}\n")


def merge_json_to_csv(
    outputs_dir: Optional[str] = None,
    csv_path: Optional[str] = None,
    append: bool = True
):
    """
    JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ CSVë¡œ ë³€í™˜
    
    Args:
        outputs_dir: outputs ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ./outputs)
        csv_path: ì¶œë ¥í•  CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ./community_data.csv)
        append: ê¸°ì¡´ CSVì— ì¶”ê°€í• ì§€ ì—¬ë¶€ (Falseë©´ ìƒˆë¡œ ì‘ì„±)
    """
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    if outputs_dir is None:
        outputs_dir = os.path.join(os.getcwd(), "outputs")
    if csv_path is None:
        csv_path = os.path.join(os.getcwd(), "community_data.csv")
    
    print(f"ğŸ”„ JSON â†’ CSV ë³€í™˜ ì‹œì‘")
    print(f"ğŸ“ JSON ë””ë ‰í† ë¦¬: {outputs_dir}")
    print(f"ğŸ“ CSV íŒŒì¼: {csv_path}")
    
    # 1. ê¸°ì¡´ CSVì—ì„œ ë§ˆì§€ë§‰ idì™€ ê¸°ì¡´ URL ëª©ë¡ í™•ì¸
    if append:
        last_id, existing_urls = get_last_id_and_existing_urls(csv_path)
        print(f"ğŸ“Š ë§ˆì§€ë§‰ ID: {last_id}, ê¸°ì¡´ ê²Œì‹œê¸€ ìˆ˜: {len(existing_urls)}ê°œ")
    else:
        last_id = 0
        existing_urls = set()
        print(f"ğŸ“Š ìƒˆ íŒŒì¼ ìƒì„± (ID: 1ë¶€í„° ì‹œì‘)")
    
    # 2. JSON íŒŒì¼ë“¤ ë¡œë“œ
    all_posts = load_json_files(outputs_dir)
    print(f"ğŸ“¦ ì´ {len(all_posts)}ê°œ ê²Œì‹œê¸€ ë¡œë“œ ì™„ë£Œ")
    
    if not all_posts:
        print("âš ï¸ ë³€í™˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 3. CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¤‘ë³µ ì œê±°)
    csv_rows = convert_to_csv_format(all_posts, last_id, existing_urls)
    
    if csv_rows:
        print(f"âœ… {len(csv_rows)}ê°œ ê²Œì‹œê¸€ ë³€í™˜ ì™„ë£Œ (ID: {last_id + 1} ~ {last_id + len(csv_rows)})")
        
        # 4. CSV íŒŒì¼ì— ì €ì¥
        append_to_csv(csv_path, csv_rows, append)
        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
        print(f"ğŸ“Š ì´ {len(csv_rows)}ê°œ ê²Œì‹œê¸€ ì¶”ê°€ë¨")
    else:
        print("âš ï¸ ì¶”ê°€í•  ìƒˆ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ì¤‘ë³µ)")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="JSON íŒŒì¼ë“¤ì„ CSVë¡œ ë³€í™˜")
    parser.add_argument(
        "--outputs-dir",
        type=str,
        default=None,
        help="outputs ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ./outputs)"
    )
    parser.add_argument(
        "--csv-path",
        type=str,
        default=None,
        help="ì¶œë ¥í•  CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ./community_data.csv)"
    )
    parser.add_argument(
        "--new",
        action="store_true",
        help="ê¸°ì¡´ CSVë¥¼ ë®ì–´ì“°ê³  ìƒˆë¡œ ì‘ì„±"
    )
    
    args = parser.parse_args()
    
    merge_json_to_csv(
        outputs_dir=args.outputs_dir,
        csv_path=args.csv_path,
        append=not args.new
    )

